{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Goal:\n",
    "\n",
    "provide a plaintext interface to analyze step-by-step what is happening in the encrypted code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54bc0082"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91303fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T00:27:44.415275Z",
     "start_time": "2024-02-19T00:27:44.410357Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8a827",
   "metadata": {},
   "source": [
    "# Load and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31e34725-f22a-4ce4-bc21-3967727b0d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T00:27:44.920562Z",
     "start_time": "2024-02-19T00:27:44.915225Z"
    }
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "def load_data(num_samples, compare_to_r_ref):\n",
    "    x_file = \"../data/X_norm_1024.csv\"\n",
    "    y_file = \"../data/y_1024.csv\"\n",
    "    train_x = pd.read_csv(x_file)\n",
    "    train_x = train_x.to_numpy()[:num_samples]\n",
    "    train_y = pd.read_csv(y_file)\n",
    "    train_y = train_y.to_numpy()[:num_samples]\n",
    "    print(f\"{bcolors.OKGREEN}Using subsampled data to compare Python-C++{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKGREEN}Reading in {x_file}, {y_file} {bcolors.ENDC}\")\n",
    "\n",
    "    print(f\"Train X shape is: {train_x.shape}\")\n",
    "    print(f\"Train y shape is: {train_y.shape}\")\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mUsing subsampled data to compare Python-C++\u001B[0m\n",
      "\u001B[92mReading in ../data/X_norm_1024.csv, ../data/y_1024.csv \u001B[0m\n",
      "Train X shape is: (1024, 10)\n",
      "Train y shape is: (1024, 1)\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 1024\n",
    "COMPARE_TO_R_REF = False\n",
    "lr = 0.1\n",
    "mu = 0.1\n",
    "train_x, train_y = load_data(\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    compare_to_r_ref=COMPARE_TO_R_REF\n",
    ")\n",
    "betas = np.zeros((10, ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T00:27:45.390239Z",
     "start_time": "2024-02-19T00:27:45.383371Z"
    }
   },
   "id": "0ce32218",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def fwd(train_x, betas, dbg=False):\n",
    "    preds = train_x @ betas\n",
    "    return np.expand_dims(sigmoid(preds), -1)\n",
    "\n",
    "def calculate_gradient(train_x, train_y, betas, fwd, dbg):\n",
    "    preds = fwd(train_x, betas, dbg)\n",
    "    gradient = -train_x.T @ (train_y - preds) / len(train_y)\n",
    "    return gradient\n",
    "\n",
    "def cost(x, y, theta):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(np.matmul(x, theta))\n",
    "    t1 = np.matmul(-y.T, np.log(h))\n",
    "    t2_a = (1 - y.T)\n",
    "    t2_b = np.log(np.clip(1 - h, 0.000000000000001, np.max(1 - h)))  # Used to get numerical issues\n",
    "    t2 = np.matmul(t2_a, t2_b)\n",
    "\n",
    "    return ((t1 - t2) / m)[0]\n",
    "\n",
    "\n",
    "def vanilla(betas, epochs, lr, train_x, train_y):\n",
    "    import copy\n",
    "\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    loss_arr = [0 for _ in range(epochs)]\n",
    "    for i in range(epochs):\n",
    "        gradient = calculate_gradient(train_x, train_y, theta, fwd, dbg=False)\n",
    "        theta = theta - lr * np.squeeze(gradient)\n",
    "        loss = cost(train_x, train_y, theta)\n",
    "        if DEBUG:\n",
    "            # print(f\"Grad: {(gradient.squeeze() * lr).tolist()}\")\n",
    "            print(f\"Theta: {theta.tolist()}\")\n",
    "        print(f\"Iteration: {i} Loss: {loss}\")\n",
    "        loss_arr[i] = loss\n",
    "\n",
    "    return loss_arr, theta\n",
    "\n",
    "\n",
    "def nesterov(betas, epochs, lr, mu, train_x, train_y):\n",
    "    import copy\n",
    "\n",
    "    phi = copy.deepcopy(betas)\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    nesterov_loss = [0 for _ in range(epochs)]\n",
    "    # for i in tqdm.trange(epochs):\n",
    "    for i in range(epochs):\n",
    "        gradient = calculate_gradient(train_x, train_y, theta, fwd, dbg=False)\n",
    "        phi_prime = theta - lr * np.squeeze(gradient)\n",
    "        if i == 0:\n",
    "            theta = phi_prime\n",
    "        else:\n",
    "            theta = phi_prime + mu * (phi_prime - phi)\n",
    "        phi = phi_prime\n",
    "        loss = cost(train_x, train_y, theta)\n",
    "        if DEBUG:\n",
    "            print(f\"Grad: {(gradient.squeeze() * lr).tolist()}\")\n",
    "            print(f\"Theta: {theta.tolist()}\")\n",
    "            print(f\"Phi: {phi.tolist()}\")\n",
    "        print(f\"Iteration: {i} Loss: {loss}\")\n",
    "        nesterov_loss[i] = loss\n",
    "\n",
    "    return nesterov_loss, theta, phi\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T00:30:43.556549Z",
     "start_time": "2024-02-19T00:30:43.551346Z"
    }
   },
   "id": "9ac264a4",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Callers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c38c3ee439b2b17c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [-0.015940504807692282, 0.004660081370379265, -0.018115234375, 0.01513671875, -0.01572265625, 1.578282828284031e-05, -0.0033203125000000003, 0.0005859375000000001, 0.0009765625, 0.0]\n",
      "Iteration: 0 Loss: 0.68240883327532\n",
      "Theta: [-0.031588549745657245, 0.008797658420500704, -0.035809652796559045, 0.02958523222229394, -0.030782344042775557, -0.00034631701151048615, -0.006198271247921871, 0.0006561815513320045, 0.0017152367103748095, 0.0005105740436275761]\n",
      "Iteration: 1 Loss: 0.6723754870271551\n",
      "Theta: [-0.046949521297982175, 0.01247970505186553, -0.05309863527278311, 0.04338933125949955, -0.045229765522874284, -0.001028415157952132, -0.008690928450902899, 0.00028167972350913613, 0.0022594974386068918, 0.0014606141285014767]\n",
      "Iteration: 2 Loss: 0.6629647982176898\n",
      "Theta: [-0.06202908232831777, 0.01576520256582198, -0.06999683984169393, 0.056589264959550106, -0.05911065548084562, -0.00197977709643906, -0.010848566314179332, -0.0004751963750072131, 0.0026470025389547843, 0.0027876348247405204]\n",
      "Iteration: 3 Loss: 0.6541089871753827\n",
      "Theta: [-0.07683308933225212, 0.018705913467334717, -0.08651820678797797, 0.069221975975757, -0.07246619351834827, -0.003156113147128636, -0.012715344908862562, -0.0015598124887313356, 0.0029101879697522835, 0.004436928523121642]\n",
      "Iteration: 4 Loss: 0.6457518269419456\n",
      "Theta: [-0.09136753048581935, 0.0213471379778568, -0.10267598455869234, 0.08132136285798745, -0.0853334287621253, -0.004518893475705316, -0.014329938347354916, -0.002924455131222652, 0.0030768436645268933, 0.006360743258443843]\n",
      "Iteration: 5 Loss: 0.6378462476268697\n",
      "Theta: [-0.10563847795635642, 0.023728431063320794, -0.11848276697780968, 0.09291854787243428, -0.09774569524350989, -0.006034701316190588, -0.01572613945142043, -0.004527559569051594, 0.003170655591976589, 0.008517505649669715]\n",
      "Iteration: 6 Loss: 0.6303524474998257\n",
      "Theta: [-0.11965205004551335, 0.0258842675762276, -0.1339505350619325, 0.10404213691576616, -0.10973300483409211, -0.00767463439703395, -0.01693342173081122, -0.006332994824027449, 0.003211706101349936, 0.010871101388966194]\n",
      "Iteration: 7 Loss: 0.623236413068072\n",
      "Theta: [-0.13341438023235658, 0.02784464976344118, -0.1490906993325385, 0.11471846381254622, -0.12132241065708972, -0.009413759007501042, -0.017977453356448583, -0.00830941130128455, 0.0032169291815370513, 0.013390218858930675]\n",
      "Iteration: 8 Loss: 0.6164687644478971\n",
      "Theta: [-0.146931591217974, 0.029635655769856745, -0.16391414027931797, 0.12497181509911542, -0.13253833790954517, -0.011230617495765559, -0.018880561675621542, -0.010429652157574689, 0.003200520221280628, 0.0160477569581735]\n",
      "Iteration: 9 Loss: 0.6100238566343815\n"
     ]
    }
   ],
   "source": [
    "losses, weights = vanilla(betas, 10, lr, train_x, train_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T00:30:44.274874Z",
     "start_time": "2024-02-19T00:30:44.240369Z"
    }
   },
   "id": "1347e356f0838fd4",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a3d18-2a23-46e6-897a-2dc859beb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, theta, phi = nesterov(betas, 10, lr, mu, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c461ede27a986"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
