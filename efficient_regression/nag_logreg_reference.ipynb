{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bc0082",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "- provide a plaintext interface to analyze step-by-step what is happening in the encrypted code\n",
    "\n",
    "- Used as a Python sanity check because I'm not that familiar with R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91303fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T23:28:21.799287Z",
     "start_time": "2024-02-17T23:28:21.435015Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8a827",
   "metadata": {},
   "source": [
    "# Load and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e34725-f22a-4ce4-bc21-3967727b0d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T23:28:22.447556Z",
     "start_time": "2024-02-17T23:28:22.443655Z"
    }
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "def load_data(num_samples, compare_to_r_ref):\n",
    "    x_file = \"../data/X_norm_1024.csv\"\n",
    "    y_file = \"../data/y_1024.csv\"\n",
    "    train_x = pd.read_csv(x_file)\n",
    "    train_x = train_x.to_numpy()[:num_samples]\n",
    "    train_y = pd.read_csv(y_file)\n",
    "    train_y = train_y.to_numpy()[:num_samples]\n",
    "    print(f\"{bcolors.OKGREEN}Using subsampled data to compare Python-C++{bcolors.ENDC}\")\n",
    "    print(f\"{bcolors.OKGREEN}Reading in {x_file}, {y_file} {bcolors.ENDC}\")\n",
    "\n",
    "    print(f\"Train X shape is: {train_x.shape}\")\n",
    "    print(f\"Train y shape is: {train_y.shape}\")\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 1024\n",
    "COMPARE_TO_R_REF = False\n",
    "lr = 0.1\n",
    "mu = 0.1\n",
    "train_x, train_y = load_data(\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    compare_to_r_ref=COMPARE_TO_R_REF\n",
    ")\n",
    "betas = np.zeros((10, ))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "0ce32218",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def fwd(train_x, betas, dbg=False):\n",
    "    preds = train_x @ betas\n",
    "    return np.expand_dims(sigmoid(preds), -1)\n",
    "\n",
    "def calculate_gradient(train_x, train_y, betas, fwd, dbg):\n",
    "    preds = fwd(train_x, betas, dbg)\n",
    "    gradient = -train_x.T @ (train_y - preds) / len(train_y)\n",
    "    return gradient\n",
    "\n",
    "def cost(x, y, theta):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(np.matmul(x, theta))\n",
    "    t1 = np.matmul(-y.T, np.log(h))\n",
    "    t2_a = (1 - y.T)\n",
    "    t2_b = np.log(np.clip(1 - h, 0.000000000000001, np.max(1 - h)))  # Used to get numerical issues\n",
    "    t2 = np.matmul(t2_a, t2_b)\n",
    "\n",
    "    return ((t1 - t2) / m)[0]\n",
    "\n",
    "def nesterov(betas, epochs, lr, mu, train_x, train_y):\n",
    "    import copy\n",
    "\n",
    "    phi = copy.deepcopy(betas)\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    nesterov_loss = [0 for _ in range(epochs)]\n",
    "    # for i in tqdm.trange(epochs):\n",
    "    for i in range(epochs):\n",
    "        gradient = calculate_gradient(train_x, train_y, theta, fwd, dbg=False)\n",
    "        phi_prime = theta - lr * np.squeeze(gradient)\n",
    "        if i == 0:\n",
    "            theta = phi_prime\n",
    "        else:\n",
    "            theta = phi_prime + mu * (phi_prime - phi)\n",
    "        phi = phi_prime\n",
    "        loss = cost(train_x, train_y, theta)\n",
    "        if DEBUG:\n",
    "            print(f\"Grad: {(gradient.squeeze() * lr).tolist()}\")\n",
    "            print(f\"Theta: {theta.tolist()}\")\n",
    "            print(f\"Phi: {phi.tolist()}\")\n",
    "        print(f\"Iteration: {i} Loss: {loss}\")\n",
    "        nesterov_loss[i] = loss\n",
    "\n",
    "        # print(f\"New loss: {cost(train_x, train_y, v)[0]}\")\n",
    "    return nesterov_loss, theta, phi\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T23:28:23.549826Z",
     "start_time": "2024-02-17T23:28:23.545850Z"
    }
   },
   "id": "9ac264a4",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a3d18-2a23-46e6-897a-2dc859beb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, theta, phi = nesterov(betas, 100, lr, mu, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5c461ede27a986"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
