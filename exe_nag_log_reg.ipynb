{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Solution for NAG logistic regression exercise\n",
    "################################################\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import openfhe\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "from efficient_regression.crypto_utils import create_crypto\n",
    "from efficient_regression.lr_train_funcs import sol_logreg_calculate_grad, compute_loss, exe_logreg_calculate_grad\n",
    "from efficient_regression.utils import next_power_of_2, collate_one_d_mat_to_ct, mat_to_ct_mat_row_major, \\\n",
    "    one_d_mat_to_vec_col_cloned_ct, get_raw_value_from_ct\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "CT = openfhe.Ciphertext\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "def load_data(x_file, y_file) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    Xs = pd.read_csv(x_file).to_numpy()\n",
    "    ys = pd.read_csv(y_file).to_numpy()\n",
    "    return Xs, ys, Xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a3240",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a29c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_nag_mask(\n",
    "        padded_row_size,\n",
    "        padded_col_size,\n",
    "        num_slots: int,\n",
    "        cc: openfhe.CryptoContext,\n",
    "        keys: openfhe.KeyPair,\n",
    ") -> Tuple[openfhe.Plaintext, openfhe.Plaintext]:\n",
    "    \"\"\"\n",
    "    Sets up all the relevant ciphertexts for machine learning including:\n",
    "        - dataset\n",
    "        - weights\n",
    "        - optimizations\n",
    "    \"\"\"\n",
    "    if padded_row_size * padded_col_size != num_slots:\n",
    "        raise Exception(\"Padded row and col size must equal to number of slots\")\n",
    "    rotation_indices = [-padded_row_size, padded_row_size]\n",
    "    cc.EvalRotateKeyGen(keys.secretKey, rotation_indices)\n",
    "\n",
    "    # For the nesterov-accelerated gradients\n",
    "    theta_mask = [0 for _ in range(num_slots)]\n",
    "    phi_mask = [0 for _ in range(num_slots)]\n",
    "\n",
    "    for i in range(num_slots):\n",
    "        if (i // padded_row_size) % 2 == 0:\n",
    "            theta_mask[i] = 1\n",
    "        else:\n",
    "            phi_mask[i] = 1\n",
    "\n",
    "    return cc.MakeCKKSPackedPlaintext(theta_mask), cc.MakeCKKSPackedPlaintext(phi_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ee73c",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_theta_phi(cc, ct_weights, theta_mask, phi_mask,padded_row_size):\n",
    "    ################################################\n",
    "    # Exe: extract the individual thetas and phis using the mask.\n",
    "    #       This involves masking, rotating and adding\n",
    "    ################################################\n",
    "\n",
    "    raise NotImplementedError(\"Implement the masking and extraction of theta and phi from the single ciphertext in extract_theta_phi\")\n",
    "\n",
    "\n",
    "def repack_theta_phi(cc, ct_theta, theta_mask, ct_phi, phi_mask):\n",
    "    ################################################\n",
    "    # Exe: re-pack the ct_theta and ct_phi back into a single ciphertext\n",
    "    #       to reduce the number of bootstraps\n",
    "    ################################################\n",
    "    raise NotImplementedError(\"Implement the re-packing of theta and phi into a single ciphertext in repack_theta_phi\")\n",
    "\n",
    "\n",
    "def reduce_noise(\n",
    "        cc,\n",
    "        ct_weights,\n",
    "        should_run_bootstrap,\n",
    "        num_slots_boot,\n",
    "        kp\n",
    "\n",
    "):\n",
    "    ################################################\n",
    "    # Exe: handle noise refreshing for both the bootstrap and iterative\n",
    "    #       mode.\n",
    "    #      See what happens if you forget to set the number-of-iterations in EvalBootstrap\n",
    "    ################################################\n",
    "    raise NotImplementedError(\"implement noise-reduction for the ct_weights in reduce_noise\")\n",
    "\n",
    "\n",
    "\n",
    "def update_phi_and_theta(cc, ct_theta, ct_phi, ct_gradient, curr_epoch, lr_eta):\n",
    "    ################################################\n",
    "    # Exe: update the theta and phi values. If you're not familiat with\n",
    "    #       NAG, please reference our logreg_reference.ipynb code\n",
    "    ################################################\n",
    "    raise NotImplementedError(\"implement the phi and theta update in update_phi_and_theta\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c5a91",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf79945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"efficient_regression/config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "logging.basicConfig(format=\"[%(filename)s:%(lineno)s - %(funcName)s] %(message)s\",\n",
    "                    level=getattr(logging, config[\"logging_level\"]))\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.debug(\"ML Params\")\n",
    "logger.debug(config[\"ml_params\"])\n",
    "logger.debug(\"Crypto Params\")\n",
    "logger.debug(config[\"crypto_params\"])\n",
    "logger.debug(\"Chebyshev Params\")\n",
    "logger.debug(config[\"chebyshev_params\"])\n",
    "if config[\"crypto_params\"][\"run_bootstrap\"]:\n",
    "    logger.info(\"Running with Bootstrap\")\n",
    "    logger.debug(config[\"crypto_bootstrap_params\"])\n",
    "ml_conf = config[\"ml_params\"]\n",
    "lr_gamma = ml_conf[\"lr_gamma\"]\n",
    "lr_eta = ml_conf[\"lr_eta\"]\n",
    "epochs = ml_conf[\"epochs\"]\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_data(ml_conf[\"x_file\"], ml_conf[\"y_file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf5a63",
   "metadata": {},
   "source": [
    "## Crypto Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_num_samples, original_num_features = x_train.shape\n",
    "beta = [[0.0] for _ in range(original_num_features)]\n",
    "\n",
    "logger.debug(\"Generating crypto objects\")\n",
    "cc, kp, num_slots = create_crypto(\n",
    "    crypto_hparams=config[\"crypto_params\"],\n",
    "    bootstrap_hparams=config[\"crypto_bootstrap_params\"]\n",
    ")\n",
    "logger.debug(\"Generating crypto objects\")\n",
    "padded_row_size = next_power_of_2(original_num_features)\n",
    "padded_col_size = num_slots / padded_row_size\n",
    "theta_mask, phi_mask = generate_nag_mask(\n",
    "    padded_row_size,\n",
    "    padded_col_size,\n",
    "    num_slots,\n",
    "    cc,\n",
    "    kp\n",
    ")\n",
    "\n",
    "# Optimization: reduces the mult depth by 1\n",
    "# NOTE: we don't actually do the transpose. This is because when we use it later on\n",
    "#   we treat it as a col matrix, as opposed to a row matrix.\n",
    "neg_x_train_T = -1 * x_train * (lr_gamma / len(x_train))\n",
    "\n",
    "logger.debug(\"Generating the Sum keys\")\n",
    "eval_sum_row_keys = cc.EvalSumRowsKeyGen(kp.secretKey, rowSize=padded_row_size)\n",
    "eval_sum_col_keys = cc.EvalSumColsKeyGen(kp.secretKey)\n",
    "\n",
    "# Encrypt the weights\n",
    "# https://github.com/openfheorg/openfhe-logreg-training-examples/blob/main/lr_nag.cpp#L302\n",
    "logger.debug(\"Generating Weights ciphertext\")\n",
    "ct_weights = collate_one_d_mat_to_ct(cc, beta, beta, padded_row_size, num_slots, kp)\n",
    "\n",
    "logger.debug(\"Generating X-ciphertext\")\n",
    "ct_x_train = mat_to_ct_mat_row_major(\n",
    "    cc,\n",
    "    x_train.tolist(),\n",
    "    padded_row_size,\n",
    "    num_slots,\n",
    "    kp\n",
    ")\n",
    "ct_neg_x_train_T = mat_to_ct_mat_row_major(\n",
    "    cc,\n",
    "    neg_x_train_T.tolist(),\n",
    "    padded_row_size,\n",
    "    num_slots,\n",
    "    kp\n",
    ")\n",
    "\n",
    "logger.debug(\"Generating y-ciphertext\")\n",
    "ct_y = one_d_mat_to_vec_col_cloned_ct(\n",
    "    cc,\n",
    "    y_train.tolist(),\n",
    "    padded_row_size,\n",
    "    num_slots,\n",
    "    kp\n",
    ")\n",
    "\n",
    "#   https://github.com/openfheorg/openfhe-logreg-training-examples/blob/main/lr_nag.cpp#L311\n",
    "num_features_enc = next_power_of_2(original_num_features)\n",
    "num_slots_boot = num_features_enc * 8\n",
    "if config[\"crypto_params\"][\"run_bootstrap\"]:\n",
    "    logger.info(\"Enabling FHE features for bootstrap\")\n",
    "    bootstrap_hparams = config[\"crypto_bootstrap_params\"]\n",
    "    level_budget = bootstrap_hparams[\"level_budget\"]\n",
    "    bsgs_dim = bootstrap_hparams[\"bsgs_dim\"]\n",
    "    cc.Enable(openfhe.PKESchemeFeature.FHE)\n",
    "    cc.EvalBootstrapSetup(level_budget, bsgs_dim, num_slots_boot)\n",
    "    cc.EvalBootstrapKeyGen(kp.secretKey, num_slots_boot)\n",
    "    logger.debug(\"Bootstrap set up\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3932b",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaae2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_epoch in range(epochs):\n",
    "\n",
    "    # print(f\"************************************************************\\nIteration: {curr_epoch}\")\n",
    "\n",
    "    if curr_epoch > 0:\n",
    "        ct_weights = reduce_noise(\n",
    "            cc=cc,\n",
    "            ct_weights=ct_weights,\n",
    "            should_run_bootstrap=config[\"crypto_params\"][\"run_bootstrap\"],\n",
    "            num_slots_boot=num_slots_boot,\n",
    "            kp = kp\n",
    "        )\n",
    "\n",
    "    ct_theta, ct_phi = extract_theta_phi(cc, ct_weights, theta_mask, phi_mask, padded_row_size)\n",
    "\n",
    "    ################################################\n",
    "    # Extract the weights\n",
    "    ################################################\n",
    "\n",
    "\n",
    "    # Exe: Navigate to the exercise function for an extra difficult problem. If for time constraints you want to\n",
    "    #       skip this (or come back to this later), comment out the first line and uncomment the second.\n",
    "    ct_gradient = exe_logreg_calculate_grad(\n",
    "#     ct_gradient = sol_logreg_calculate_grad(\n",
    "        cc,\n",
    "        ct_x_train,\n",
    "        ct_neg_x_train_T,\n",
    "        ct_y,\n",
    "        ct_theta,\n",
    "        row_size=padded_row_size,\n",
    "        row_sum_keymap=eval_sum_row_keys,\n",
    "        col_sum_keymap=eval_sum_col_keys,\n",
    "        cheb_range_start=config[\"chebyshev_params\"][\"lower_bound\"],\n",
    "        cheb_range_end=config[\"chebyshev_params\"][\"upper_bound\"],\n",
    "        cheb_poly_degree=config[\"chebyshev_params\"][\"polynomial_degree\"],\n",
    "        kp=kp\n",
    "    )\n",
    "    ################################################\n",
    "    # Note: Formulation of NAG update based on\n",
    "    #   https://eprint.iacr.org/2018/462.pdf, Algorithm 1 and\n",
    "    #   https://jlmelville.github.io/mize/nesterov.html\n",
    "    ################################################\n",
    "\n",
    "    if ct_gradient is None:\n",
    "        raise Exception(\"You either \"\n",
    "                        \"\\ni) have not implemented exe_logreg_calculate_grad or \"\n",
    "                        \"\\nii) forgot to flip the function call to sol_logreg_calculate_grad\")\n",
    "\n",
    "    ct_theta, ct_phi = update_phi_and_theta(cc, ct_theta, ct_phi, ct_gradient, curr_epoch, lr_eta)\n",
    "\n",
    "    if config[\"RUN_IN_DEBUG\"]:\n",
    "        clear_theta = get_raw_value_from_ct(cc, ct_theta, kp, original_num_features)\n",
    "        loss = compute_loss(beta=clear_theta, X=x_train, y=y_train)\n",
    "\n",
    "        clear_phi = get_raw_value_from_ct(cc, ct_phi, kp, original_num_features)\n",
    "\n",
    "        clear_grads = get_raw_value_from_ct(cc, ct_gradient, kp, original_num_features * 2)\n",
    "        logger.debug(f\"Grad: {clear_grads}\")\n",
    "        logger.debug(f\"Theta: {clear_theta}\")\n",
    "        logger.debug(f\"Phi: {clear_phi}\")\n",
    "        logger.info(f\"Iteration: {curr_epoch} Loss: {loss}\")\n",
    "\n",
    "    # Repacking the two ciphertexts back into a single ciphertext\n",
    "    ct_weights = repack_theta_phi(cc, ct_theta, theta_mask, ct_phi, phi_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39751fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
