{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Solution for logistic regression exercise\n",
    "################################################\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import openfhe\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "from efficient_regression.crypto_utils import create_crypto\n",
    "from efficient_regression.lr_train_funcs import sol_logreg_calculate_grad, compute_loss, exe_logreg_calculate_grad\n",
    "from efficient_regression.utils import next_power_of_2, collate_one_d_mat_to_ct, mat_to_ct_mat_row_major, \\\n",
    "    one_d_mat_to_vec_col_cloned_ct, get_raw_value_from_ct, encrypt_weights\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "CT = openfhe.Ciphertext\n",
    "CC = openfhe.CryptoContext\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(x_file, y_file) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    Xs = pd.read_csv(x_file).to_numpy()\n",
    "    ys = pd.read_csv(y_file).to_numpy()\n",
    "    return Xs, ys, Xs, ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca669ece",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1569518",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_weights(cc: CC, ct_weights: CT, grads: CT, lr: float):\n",
    "    ################################################\n",
    "    # Exe: Implement a gradient step.\n",
    "    # Functions you may find useful:\n",
    "    #   - cc.EvalSub\n",
    "    #   - cc.EvalMult\n",
    "    ################################################\n",
    "    raise NotImplementedError(\"You'll want to implement the weight update in the update_weights\")\n",
    "\n",
    "\n",
    "def reduce_noise(\n",
    "        cc,\n",
    "        ct_weights,\n",
    "        should_run_bootstrap,\n",
    "        num_slots_boot,\n",
    "        kp\n",
    "):\n",
    "    ################################################\n",
    "    # Exe: handle noise refreshing for both the bootstrap and iterative\n",
    "    #       mode.\n",
    "    #      See what happens if you forget to set the number-of-iterations in EvalBootstrap\n",
    "    ################################################\n",
    "\n",
    "    raise NotImplementedError(\"You'll want to implement the ciphertext noise reduction in reduce_noise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edceffb2",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "## Config Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"efficient_regression/config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "logging.basicConfig(format=\"[%(filename)s:%(lineno)s - %(funcName)s] %(message)s\",\n",
    "                    level=getattr(logging, config[\"logging_level\"]))\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.debug(\"ML Params\")\n",
    "logger.debug(config[\"ml_params\"])\n",
    "logger.debug(\"Crypto Params\")\n",
    "logger.debug(config[\"crypto_params\"])\n",
    "logger.debug(\"Chebyshev Params\")\n",
    "logger.debug(config[\"chebyshev_params\"])\n",
    "if config[\"crypto_params\"][\"run_bootstrap\"]:\n",
    "    logger.info(\"Running with Bootstrap\")\n",
    "    logger.debug(config[\"crypto_bootstrap_params\"])\n",
    "ml_conf = config[\"ml_params\"]\n",
    "lr_gamma = ml_conf[\"lr_gamma\"]\n",
    "lr_eta = ml_conf[\"lr_eta\"]\n",
    "epochs = ml_conf[\"epochs\"]\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_data(ml_conf[\"x_file\"], ml_conf[\"y_file\"])\n",
    "\n",
    "original_num_samples, original_num_features = x_train.shape\n",
    "beta = [[0.0] for _ in range(original_num_features)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aed66e",
   "metadata": {},
   "source": [
    "## Crypto Objects Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32964931",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"Generating crypto objects\")\n",
    "cc, kp, num_slots = create_crypto(\n",
    "    crypto_hparams=config[\"crypto_params\"],\n",
    "    bootstrap_hparams=config[\"crypto_bootstrap_params\"]\n",
    ")\n",
    "logger.debug(\"Generating crypto objects\")\n",
    "padded_row_size = next_power_of_2(original_num_features)\n",
    "padded_col_size = num_slots / padded_row_size\n",
    "\n",
    "# Exe: reduces the mult depth by 1\n",
    "# NOTE: we don't actually do the transpose. This is because when we use it later on\n",
    "#   we treat it as a col matrix, as opposed to a row matrix.\n",
    "neg_x_train_T = -1 * x_train * (1 / len(x_train))\n",
    "\n",
    "logger.debug(\"Generating the Sum keys\")\n",
    "eval_sum_row_keys = cc.EvalSumRowsKeyGen(kp.secretKey, rowSize=padded_row_size)\n",
    "eval_sum_col_keys = cc.EvalSumColsKeyGen(kp.secretKey)\n",
    "\n",
    "# Encrypt the weights\n",
    "logger.debug(\"Generating Weights ciphertext\")\n",
    "ct_weights = encrypt_weights(cc, kp, beta)\n",
    "\n",
    "logger.debug(\"Generating X-ciphertext\")\n",
    "ct_x_train = mat_to_ct_mat_row_major(\n",
    "    cc,\n",
    "    x_train.tolist(),\n",
    "    padded_row_size,\n",
    "    num_slots,\n",
    "    kp\n",
    ")\n",
    "ct_neg_x_train_T = mat_to_ct_mat_row_major(\n",
    "    cc,\n",
    "    neg_x_train_T.tolist(),\n",
    "    padded_row_size,\n",
    "    num_slots,\n",
    "    kp\n",
    ")\n",
    "\n",
    "logger.debug(\"Generating y-ciphertext\")\n",
    "ct_y = one_d_mat_to_vec_col_cloned_ct(\n",
    "    cc,\n",
    "    y_train.tolist(),\n",
    "    padded_row_size,\n",
    "    num_slots,\n",
    "    kp\n",
    ")\n",
    "\n",
    "num_features_enc = next_power_of_2(original_num_features)\n",
    "num_slots_boot = num_features_enc * 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78745686",
   "metadata": {},
   "source": [
    "## Running Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"crypto_params\"][\"run_bootstrap\"]:\n",
    "    logger.info(\"Enabling FHE features for bootstrap\")\n",
    "    bootstrap_hparams = config[\"crypto_bootstrap_params\"]\n",
    "    level_budget = bootstrap_hparams[\"level_budget\"]\n",
    "    bsgs_dim = bootstrap_hparams[\"bsgs_dim\"]\n",
    "    cc.Enable(openfhe.PKESchemeFeature.FHE)\n",
    "    cc.EvalBootstrapSetup(level_budget, bsgs_dim, num_slots_boot)\n",
    "    cc.EvalBootstrapKeyGen(kp.secretKey, num_slots_boot)\n",
    "    logger.debug(\"Bootstrap set up\")\n",
    "\n",
    "for curr_epoch in range(epochs):\n",
    "\n",
    "    # print(f\"************************************************************\\nIteration: {curr_epoch}\")\n",
    "\n",
    "    if curr_epoch > 0:\n",
    "        ct_weights = reduce_noise(\n",
    "            cc=cc,\n",
    "            ct_weights=ct_weights,\n",
    "            should_run_bootstrap=config[\"crypto_params\"][\"run_bootstrap\"],\n",
    "            num_slots_boot=num_slots_boot,\n",
    "            kp = kp\n",
    "        )\n",
    "\n",
    "    ################################################\n",
    "    # Extract the weights\n",
    "    ################################################\n",
    "\n",
    "    # Exe: Navigate to the exercise function for an extra difficult problem. If for time constraints you want to\n",
    "    #       skip this (or come back to this later), comment out the first line and uncomment the second.\n",
    "\n",
    "    # Exe: Navigate to the exercise function for an extra difficult problem. If for time constraints you want to\n",
    "    #       skip this (or come back to this later), comment out the first line and uncomment the second.\n",
    "#     ct_gradient = exe_logreg_calculate_grad(\n",
    "    ct_gradient = sol_logreg_calculate_grad(\n",
    "        cc,\n",
    "        ct_x_train,\n",
    "        ct_neg_x_train_T,\n",
    "        ct_y,\n",
    "        ct_weights,\n",
    "        row_size=padded_row_size,\n",
    "        row_sum_keymap=eval_sum_row_keys,\n",
    "        col_sum_keymap=eval_sum_col_keys,\n",
    "        cheb_range_start=config[\"chebyshev_params\"][\"lower_bound\"],\n",
    "        cheb_range_end=config[\"chebyshev_params\"][\"upper_bound\"],\n",
    "        cheb_poly_degree=config[\"chebyshev_params\"][\"polynomial_degree\"],\n",
    "        kp=kp\n",
    "    )\n",
    "\\\n",
    "    if ct_gradient is None:\n",
    "        raise Exception(\"You either \"\n",
    "                        \"\\ni) have not implemented exe_logreg_calculate_grad or \"\n",
    "                        \"\\nii) forgot to flip the function call to sol_logreg_calculate_grad\")\n",
    "\n",
    "    ct_weights = update_weights(cc, ct_weights, ct_gradient, lr_eta)\n",
    "\n",
    "    if config[\"RUN_IN_DEBUG\"]:\n",
    "        clear_theta = get_raw_value_from_ct(cc, ct_weights, kp, original_num_features)\n",
    "        loss = compute_loss(beta=clear_theta, X=x_train, y=y_train)\n",
    "\n",
    "        clear_grads = get_raw_value_from_ct(cc, ct_gradient, kp, original_num_features)\n",
    "        logger.debug(f\"Grad: {clear_grads}\")\n",
    "        logger.debug(f\"Theta: {clear_theta}\")\n",
    "        logger.info(f\"Iteration: {curr_epoch} Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd917a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
